{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boston House Price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Regression on the Boston House Price dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy import stats\n",
    "%matplotlib nbagg "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0     1     2    3      4      5     6       7    8      9     10  \\\n",
      "0    0.00632  18.0  2.31  0.0  0.538  6.575  65.2  4.0900  1.0  296.0  15.3   \n",
      "1    0.02731   0.0  7.07  0.0  0.469  6.421  78.9  4.9671  2.0  242.0  17.8   \n",
      "2    0.02729   0.0  7.07  0.0  0.469  7.185  61.1  4.9671  2.0  242.0  17.8   \n",
      "3    0.03237   0.0  2.18  0.0  0.458  6.998  45.8  6.0622  3.0  222.0  18.7   \n",
      "4    0.06905   0.0  2.18  0.0  0.458  7.147  54.2  6.0622  3.0  222.0  18.7   \n",
      "..       ...   ...   ...  ...    ...    ...   ...     ...  ...    ...   ...   \n",
      "495  0.17899   0.0  9.69  0.0  0.585  5.670  28.8  2.7986  6.0  391.0  19.2   \n",
      "496  0.28960   0.0  9.69  0.0  0.585  5.390  72.9  2.7986  6.0  391.0  19.2   \n",
      "497  0.26838   0.0  9.69  0.0  0.585  5.794  70.6  2.8927  6.0  391.0  19.2   \n",
      "498  0.23912   0.0  9.69  0.0  0.585  6.019  65.3  2.4091  6.0  391.0  19.2   \n",
      "499  0.17783   0.0  9.69  0.0  0.585  5.569  73.5  2.3999  6.0  391.0  19.2   \n",
      "\n",
      "         11     12     13  \n",
      "0    396.90   4.98  240.0  \n",
      "1    396.90   9.14  216.0  \n",
      "2    392.83   4.03  347.0  \n",
      "3    394.63   2.94  334.0  \n",
      "4    396.90   5.33  362.0  \n",
      "..      ...    ...    ...  \n",
      "495  393.29  17.60  231.0  \n",
      "496  396.90  21.14  197.0  \n",
      "497  396.90  14.10  183.0  \n",
      "498  396.90  12.92  212.0  \n",
      "499  395.77  15.10  175.0  \n",
      "\n",
      "[500 rows x 14 columns]\n",
      "Shape of data array: (500, 14)\n"
     ]
    }
   ],
   "source": [
    "filename = \"data/house.csv\"\n",
    "Data = np.genfromtxt(filename, delimiter=';',skip_header=1)\n",
    "np.random.seed(1216127)\n",
    "dataDescription = pd.DataFrame(Data)\n",
    "print(dataDescription)\n",
    "\n",
    "print (\"Shape of data array: \" + str(Data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of samples:  500\n",
      "Size of each chunk of data:  125\n",
      "Training input data size:  (250, 13)\n",
      "Training output data size:  (250,)\n",
      "Validation input data size:  (125, 13)\n",
      "Validation output data size:  (125,)\n",
      "Test input data size:  (125, 13)\n",
      "Test output data size:  (125,)\n"
     ]
    }
   ],
   "source": [
    "#Split data in training, validation and test sets\n",
    "\n",
    "num_total_samples = Data.shape[0]   #number of total samples\n",
    "print (\"Total number of samples: \", num_total_samples)\n",
    "\n",
    "size_chunk = int(num_total_samples/4.)\n",
    "print (\"Size of each chunk of data: \", size_chunk)\n",
    "\n",
    "np.random.shuffle(Data)\n",
    "\n",
    "\n",
    "#training data \n",
    "X_training = np.delete(Data[:size_chunk*2],4,1) \n",
    "Y_training = Data[:size_chunk*2, 4] \n",
    "print (\"Training input data size: \", X_training.shape)\n",
    "print (\"Training output data size: \", Y_training.shape)\n",
    "\n",
    "#validation data\n",
    "X_validation = np.delete(Data[size_chunk:size_chunk*2],4,1) \n",
    "Y_validation = Data[size_chunk:size_chunk*2, 4] #\n",
    "print (\"Validation input data size: \", X_validation.shape)\n",
    "print (\"Validation output data size: \", Y_validation.shape)\n",
    "\n",
    "#test data\n",
    "X_test = np.delete(Data[size_chunk*3:num_total_samples],4,1)\n",
    "Y_test = Data[size_chunk*3: num_total_samples, 4] \n",
    "print (\"Test input data size: \", X_test.shape)\n",
    "print (\"Test output data size: \", Y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of the training input data: [-1.50990331e-17  4.48530102e-17  1.30828681e-15 -3.90798505e-17\n",
      "  4.69402295e-15 -6.30606678e-16  2.84217094e-17  1.24344979e-17\n",
      " -8.52651283e-17  1.24900090e-14  3.31801253e-15 -6.35935749e-16\n",
      " -1.59872116e-16]\n",
      "Std of the training input data: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "Mean of the validation input data: [ 4.38666850e-02  1.48784654e-02  3.66804530e-02 -9.23705556e-17\n",
      " -1.45015514e-02  6.91248955e-02 -2.91166258e-02  6.26999154e-02\n",
      "  7.59580453e-02  2.15380787e-02 -4.40790131e-02  1.28998886e-02\n",
      " -6.18782496e-02]\n",
      "Std of the validation input data: [0.97171696 1.02093339 1.00061709 1.         0.94892189 0.9663695\n",
      " 1.03985199 1.03456623 1.00739696 1.02490885 1.04436978 0.92036048\n",
      " 0.97924319]\n",
      "Mean of the test input data: [ 1.47879101e-01  1.89678160e-01 -3.73805730e-02  1.91846539e-16\n",
      "  8.14216646e-02  3.52975211e-02  2.79668526e-02  2.17490332e-01\n",
      "  2.02182444e-01  6.24052024e-02  8.52134185e-03 -2.65918757e-02\n",
      "  4.07117450e-02]\n",
      "Std of the test input data: [1.00290671 1.23989769 1.04135913 1.         1.04753836 0.98101744\n",
      " 1.10256508 1.12956414 1.1301758  0.95239745 1.04742204 1.02715439\n",
      " 1.12421342]\n"
     ]
    }
   ],
   "source": [
    "#Data Normalization\n",
    "\n",
    "# standardization of input matrix\n",
    "from sklearn import preprocessing\n",
    "scaler = preprocessing.StandardScaler().fit(X_training) \n",
    "\n",
    "X_training = scaler.transform(X_training)\n",
    "print (\"Mean of the training input data:\", X_training.mean(axis=0))\n",
    "print (\"Std of the training input data:\",X_training.std(axis=0))\n",
    "\n",
    "X_validation = scaler.transform(X_validation) \n",
    "print (\"Mean of the validation input data:\", X_validation.mean(axis=0))\n",
    "print (\"Std of the validation input data:\", X_validation.std(axis=0))\n",
    "\n",
    "X_test = scaler.transform(X_test) \n",
    "print (\"Mean of the test input data:\", X_test.mean(axis=0))\n",
    "print (\"Std of the test input data:\", X_test.std(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250, 14)\n",
      "(125, 14)\n",
      "(125, 14)\n",
      "LS coefficients by hand: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "LS coefficients with numpy lstsq: [ 0.5524756  -0.00728943  0.00144989  0.02622363  0.00209314 -0.0020156\n",
      "  0.02438197 -0.04234038  0.01592126  0.01879322 -0.03404697 -0.0068781\n",
      " -0.00625954 -0.0257516 ]\n",
      "RSS by hand: 79.88972503\n",
      "RSS with numpy lstsq:  [0.74304283]\n",
      "Empirical risk by hand: 0.31955890012\n",
      "Empirical risk with numpy lstsq: [0.00297217]\n"
     ]
    }
   ],
   "source": [
    "#Model Training\n",
    "\n",
    "#linear regression coefficients for training data\n",
    "arr_x1 = np.ones([250, 1]) \n",
    "X_training1 = np.hstack((arr_x1, X_training))\n",
    "print(X_training1.shape)\n",
    "\n",
    "arr_x2 = np.ones([125, 1])\n",
    "X_validation1 = np.hstack((arr_x2, X_validation))\n",
    "print(X_validation1.shape)\n",
    "\n",
    "arr_x3 = np.ones([125, 1])\n",
    "X_test1 = np.hstack((arr_x3, X_test))\n",
    "print(X_test1.shape)\n",
    "\n",
    "                     \n",
    "#the least-squares algorithm\n",
    "U, sigma, VT = np.linalg.svd(np.dot(np.transpose(X_training1), X_training1)) \n",
    "\n",
    "arr_sigma = np.array(np.zeros(len(sigma)))\n",
    "rate = 1e-20\n",
    "\n",
    "for k in range(len(sigma)):\n",
    "    if arr_sigma[k] > rate:\n",
    "        arr_sigma[k] = 1/sigma[k]\n",
    "    else:\n",
    "        arr_sigma[k] = 0.\n",
    "            \n",
    "sigma1 = np.dot(U, np.dot(np.diag(arr_sigma), VT))\n",
    "w_hand = np.dot(np.dot(sigma1, np.transpose(X_training1)), Y_training) #PLACE HERE YOUR SOLUTION\n",
    "\n",
    "\n",
    "#the least-squares coefficients using linalg.lstsq\n",
    "w_np, RSStr_np, rank_Xtr, sv_Xtr = np.linalg.lstsq(X_training1, Y_training, rcond=None)\n",
    "print(\"LS coefficients by hand:\", w_hand)\n",
    "print(\"LS coefficients with numpy lstsq:\", w_np)\n",
    "\n",
    "#Residual sums of squares by hand\n",
    "RSStr_hand = np.linalg.norm(Y_training - np.dot(X_training1, w_hand))**2 # COMPLETE\n",
    "m_training = X_training1.shape[0]\n",
    "print(\"RSS by hand:\",  RSStr_hand)\n",
    "print(\"RSS with numpy lstsq: \", RSStr_np)\n",
    "print(\"Empirical risk by hand:\", RSStr_hand/m_training)\n",
    "print(\"Empirical risk with numpy lstsq:\", RSStr_np/m_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSS on validation data: 41.57736982000001\n",
      "Loss estimated from validation data: 0.33261895856000007\n",
      "Measure on Training Data (1-R^2): -0.04694703968476843\n",
      "Measure on Validation Data(1-R^2): -0.05075293309643558\n",
      "Measure on Test Data(1-R^2): -0.0437066904634853\n"
     ]
    }
   ],
   "source": [
    "#Data Prediction\n",
    "\n",
    "#prediction_training \n",
    "prediction_training = np.dot(X_training1, w_hand) \n",
    "prediction_validation = np.dot(X_validation1, w_hand) \n",
    "prediction_test = np.dot(X_test1, w_hand) \n",
    "\n",
    "#the loss for points in the validation and test data\n",
    "RSS_training = np.sum((Y_training - prediction_training)**2) \n",
    "RSS_validation = np.sum((Y_validation - prediction_validation)**2)   \n",
    "RSS_test = np.sum((Y_test - prediction_test)**2)    \n",
    "\n",
    "m_validation = X_validation.shape[0]\n",
    "print(\"RSS on validation data:\",  RSS_validation)\n",
    "print(\"Loss estimated from validation data:\", RSS_validation/m_validation)\n",
    "\n",
    "TSS_training = np.sum((np.mean(Y_training) - prediction_training)**2)\n",
    "TSS_validation = np.sum((np.mean(Y_validation) - prediction_validation)**2) \n",
    "TSS_test = np.sum((np.mean(Y_test) - prediction_test)**2)\n",
    "\n",
    "#another measurement of linear fit is given by 1 - R^2\n",
    "measure_training = 1 - (RSS_training/TSS_training)  \n",
    "measure_validation = 1 - (RSS_validation/TSS_validation)  \n",
    "measure_test = 1 - (RSS_test/TSS_test) \n",
    "\n",
    "print(\"Measure on Training Data (1-R^2):\", measure_training)\n",
    "print(\"Measure on Validation Data(1-R^2):\", measure_validation)\n",
    "print(\"Measure on Test Data(1-R^2):\", measure_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
