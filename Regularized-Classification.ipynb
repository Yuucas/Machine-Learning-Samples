{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularized Classification on Student Alcohol Dataset\n",
    "\n",
    "The dataset is gathered from Kaggle (https://www.kaggle.com/uciml/student-alcohol-consumption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "%matplotlib inline  \n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(521212)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>drink_alcohol</th>\n",
       "      <th>age</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>traveltime</th>\n",
       "      <th>studytime</th>\n",
       "      <th>famrel</th>\n",
       "      <th>freetime</th>\n",
       "      <th>goout</th>\n",
       "      <th>health</th>\n",
       "      <th>absences</th>\n",
       "      <th>Marks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>649.000000</td>\n",
       "      <td>649.000000</td>\n",
       "      <td>649.000000</td>\n",
       "      <td>649.000000</td>\n",
       "      <td>649.000000</td>\n",
       "      <td>649.000000</td>\n",
       "      <td>649.000000</td>\n",
       "      <td>649.000000</td>\n",
       "      <td>649.000000</td>\n",
       "      <td>649.000000</td>\n",
       "      <td>649.000000</td>\n",
       "      <td>649.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.454545</td>\n",
       "      <td>16.744222</td>\n",
       "      <td>2.514638</td>\n",
       "      <td>2.306626</td>\n",
       "      <td>1.568567</td>\n",
       "      <td>1.930663</td>\n",
       "      <td>3.930663</td>\n",
       "      <td>3.180277</td>\n",
       "      <td>3.184900</td>\n",
       "      <td>3.536210</td>\n",
       "      <td>3.659476</td>\n",
       "      <td>11.906009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.498314</td>\n",
       "      <td>1.218138</td>\n",
       "      <td>1.134552</td>\n",
       "      <td>1.099931</td>\n",
       "      <td>0.748660</td>\n",
       "      <td>0.829510</td>\n",
       "      <td>0.955717</td>\n",
       "      <td>1.051093</td>\n",
       "      <td>1.175766</td>\n",
       "      <td>1.446259</td>\n",
       "      <td>4.640759</td>\n",
       "      <td>3.230656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       drink_alcohol         age        Medu        Fedu  traveltime  \\\n",
       "count     649.000000  649.000000  649.000000  649.000000  649.000000   \n",
       "mean        0.454545   16.744222    2.514638    2.306626    1.568567   \n",
       "std         0.498314    1.218138    1.134552    1.099931    0.748660   \n",
       "min         0.000000   15.000000    0.000000    0.000000    1.000000   \n",
       "25%         0.000000   16.000000    2.000000    1.000000    1.000000   \n",
       "50%         0.000000   17.000000    2.000000    2.000000    1.000000   \n",
       "75%         1.000000   18.000000    4.000000    3.000000    2.000000   \n",
       "max         1.000000   22.000000    4.000000    4.000000    4.000000   \n",
       "\n",
       "        studytime      famrel    freetime       goout      health    absences  \\\n",
       "count  649.000000  649.000000  649.000000  649.000000  649.000000  649.000000   \n",
       "mean     1.930663    3.930663    3.180277    3.184900    3.536210    3.659476   \n",
       "std      0.829510    0.955717    1.051093    1.175766    1.446259    4.640759   \n",
       "min      1.000000    1.000000    1.000000    1.000000    1.000000    0.000000   \n",
       "25%      1.000000    4.000000    3.000000    2.000000    2.000000    0.000000   \n",
       "50%      2.000000    4.000000    3.000000    3.000000    4.000000    2.000000   \n",
       "75%      2.000000    5.000000    4.000000    4.000000    5.000000    6.000000   \n",
       "max      4.000000    5.000000    5.000000    5.000000    5.000000   32.000000   \n",
       "\n",
       "            Marks  \n",
       "count  649.000000  \n",
       "mean    11.906009  \n",
       "std      3.230656  \n",
       "min      0.000000  \n",
       "25%     10.000000  \n",
       "50%     12.000000  \n",
       "75%     14.000000  \n",
       "max     19.000000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the data from the csv file\n",
    "df = pd.read_csv(\"data/student-data.csv\", sep=',')\n",
    "\n",
    "# let's see some statistics about the data \n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['drink_alcohol', 'school', 'sex', 'age', 'address', 'famsize', 'Pstatus', 'Medu', 'Fedu', 'Mjob', 'Fjob', 'guardian', 'traveltime', 'studytime', 'famrel', 'freetime', 'goout', 'health', 'absences', 'Marks']\n",
      "Number of samples: 649\n",
      "Categorical feature: school    Number of categories: (2,)\n",
      "Categorical feature: sex    Number of categories: (2,)\n",
      "Valued feature: age\n",
      "Categorical feature: address    Number of categories: (2,)\n",
      "Categorical feature: famsize    Number of categories: (2,)\n",
      "Categorical feature: Pstatus    Number of categories: (2,)\n",
      "Categorical feature: Medu    Number of categories: (5,)\n",
      "Categorical feature: Fedu    Number of categories: (5,)\n",
      "Categorical feature: Mjob    Number of categories: (5,)\n",
      "Categorical feature: Fjob    Number of categories: (5,)\n",
      "Categorical feature: guardian    Number of categories: (3,)\n",
      "Categorical feature: traveltime    Number of categories: (4,)\n",
      "Categorical feature: studytime    Number of categories: (4,)\n",
      "Categorical feature: famrel    Number of categories: (5,)\n",
      "Categorical feature: freetime    Number of categories: (5,)\n",
      "Categorical feature: goout    Number of categories: (5,)\n",
      "Categorical feature: health    Number of categories: (5,)\n",
      "Valued feature: absences\n",
      "Valued feature: Marks\n",
      "Shape of X: (649, 64)\n",
      "Sample element from X: [1.0 0.0 0.0 1.0 15 0.0 1.0 1.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0\n",
      " 0.0 1.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 1.0 0.0\n",
      " 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 1.0 0.0\n",
      " 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0 14]\n"
     ]
    }
   ],
   "source": [
    "Data = df.values\n",
    "X_categorical = Data[:,1:]\n",
    "# the target value (class) is in the first column\n",
    "Y = Data[:,0]\n",
    "\n",
    "print(list(df))\n",
    "\n",
    "# the number d of features of each sample\n",
    "d = X_categorical.shape[1]\n",
    "\n",
    "# the number m of samples\n",
    "m = X_categorical.shape[0]\n",
    "\n",
    "# the number of samples is\n",
    "print(\"Number of samples: {}\".format(m))\n",
    "\n",
    "# categorical variables using integers and one-hot-encoder\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "onehot_encoder = OneHotEncoder(categories='auto')\n",
    "\n",
    "\n",
    "# the first column of the data matrix into indicator variables\n",
    "X_tmp = label_encoder.fit_transform(X_categorical[:,0])\n",
    "X_tmp = X_tmp.reshape(X_tmp.shape[0],1)\n",
    "X = onehot_encoder.fit_transform(X_tmp[:,0].reshape(-1,1)).toarray()\n",
    "print(\"Categorical feature:\", df.columns[1], \"   Number of categories:\", X[1,:].shape)\n",
    "\n",
    "\n",
    "# repeat for the other categorical input variables\n",
    "index_categorical = [1,3,4,5,6,7,8,9,10,11,12,13,14,15,16]\n",
    "\n",
    "for i in range(1,19):\n",
    "    if i in index_categorical:\n",
    "        X_tmp = label_encoder.fit_transform(X_categorical[:,i])\n",
    "        X_tmp = X_tmp.reshape(X_tmp.shape[0],1)\n",
    "        X_tmp = onehot_encoder.fit_transform(X_tmp[:,0].reshape(-1,1)).toarray()\n",
    "        X = np.hstack((X,X_tmp))\n",
    "        print(\"Categorical feature:\", df.columns[i+1], \"   Number of categories:\", X_tmp[1,:].shape)\n",
    "    else:\n",
    "        X_tmp = X_categorical[:,i]\n",
    "        X_tmp = X_tmp.reshape(X_tmp.shape[0],1)\n",
    "        X = np.hstack((X,X_tmp))\n",
    "        print(\"Valued feature:\", df.columns[i+1])\n",
    "        \n",
    "print(\"Shape of X:\", X.shape)\n",
    "print(\"Sample element from X:\", X[20,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 2\n",
      "[1 1 0 1 0 0 0 0 1 0 1 1 0 1 0 0 1 0 1 0 0 1 0 1 0 1 0 0 1 0 0 0 1 1 0 0 1\n",
      " 1 0 0 0 1 0 1 0 0 0 1 1 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 1\n",
      " 0 0 0 1 0 0 0 0 1 1 1 1 0 1 0 1 1 0 0 1 0 1 0 1 1 1]\n",
      "0.45454545454545453\n"
     ]
    }
   ],
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "# the target labels\n",
    "Y = label_encoder.fit_transform(Y)\n",
    "K = max(Y) + 1 # number of classes\n",
    "\n",
    "print(\"Number of classes: \"+str(K))\n",
    "\n",
    "# Split data into training and validation data\n",
    "\n",
    "# number of samples\n",
    "m = np.shape(X)[0]\n",
    "\n",
    "permutation = np.random.permutation(m)\n",
    "X = X[permutation]\n",
    "Y = Y[permutation]\n",
    "\n",
    "m_training = 100 #  # 100 samples for training + validation...\n",
    "m_test = m-m_training \n",
    "\n",
    "X_training, X_test, Y_training, Y_test = train_test_split(X, Y, test_size =float(m_test)/float(m), random_state = 521212)\n",
    "\n",
    "print(Y_training)\n",
    "\n",
    "m_training = X_training.shape[0]\n",
    "m_test = X_test.shape[0]\n",
    "\n",
    "print(float(sum(Y_training)+sum(Y_test))/float(m_training+m_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.73094388 -0.73094388 -1.19993734 ... -0.78898669 -0.78915946\n",
      "  -0.28065755]\n",
      " [ 0.73094388 -0.73094388  0.83337685 ... -0.78898669 -0.78915946\n",
      "   1.26820936]\n",
      " [-1.36809408  1.36809408 -1.19993734 ...  1.2674485   1.5829708\n",
      "  -0.59043093]\n",
      " ...\n",
      " [ 0.73094388 -0.73094388  0.83337685 ... -0.78898669 -0.78915946\n",
      "   0.6486626 ]\n",
      " [ 0.73094388 -0.73094388  0.83337685 ... -0.78898669 -0.78915946\n",
      "   0.02911583]\n",
      " [ 0.73094388 -0.73094388 -1.19993734 ...  1.2674485   0.07343336\n",
      "   0.02911583]]\n"
     ]
    }
   ],
   "source": [
    "# Standardization of the Features Matrix\n",
    "from sklearn import preprocessing\n",
    "\n",
    "X = X.astype(np.float64) \n",
    "X_training = X_training.astype(np.float64)\n",
    "X_test = X_test.astype(np.float64)\n",
    "\n",
    "# the standard scaling\n",
    "scaler = preprocessing.StandardScaler().fit(X)\n",
    "\n",
    "X_training = scaler.transform(X_training)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values of parameter C tried in 10-fold Cross-Validation: [100000000]\n",
      "Accuracies obtained for the different values of C with 10-fold Cross-Validation: [0.52]\n",
      "Best value of parameter C according to 10-fold Cross-Validation: 100000000\n",
      "<class 'dict'>\n",
      "10-fold Cross-Validation accuracies obtained with the best value of parameter C: [0.8]\n"
     ]
    }
   ],
   "source": [
    "reg = linear_model.LogisticRegressionCV(Cs=[100000000], solver='newton-cg',cv=10, penalty='l2')\n",
    "\n",
    "#fit the model on training data\n",
    "reg.fit(X_training, Y_training)\n",
    "\n",
    "# the values of C evaluated in cross-validation;\n",
    "print(\"Values of parameter C tried in 10-fold Cross-Validation: {}\".format( reg.Cs_ ))\n",
    "\n",
    "# the average accuracy across the 10 folds\n",
    "CV_accuracies = np.divide(np.sum(reg.scores_[1],axis=0),10)\n",
    "\n",
    "# the average accuracies obtained for the various values of C\n",
    "print(\"Accuracies obtained for the different values of C with 10-fold Cross-Validation: {}\".format( CV_accuracies ))\n",
    "\n",
    "# the best value of C as identified by cross-validation;\n",
    "print(\"Best value of parameter C according to 10-fold Cross-Validation: {}\".format( reg.C_[0] ))\n",
    "\n",
    "# the best CV accuracy, and then print it\n",
    "print(type(reg.scores_))\n",
    "reg_best_CV_accuracy = max(reg.scores_[1])\n",
    "print(\"10-fold Cross-Validation accuracies obtained with the best value of parameter C: {}\".format( reg_best_CV_accuracy ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients obtained using the entire training set: [[ 0.88094966 -0.88094966 -0.41538158  0.41538158  0.13835414 -0.34495143\n",
      "   0.34495143  0.09470007 -0.09470007  0.03643915 -0.03643915 -3.02832882\n",
      "  -0.65225711  0.05383952  1.24919037  0.05261164 -0.01878807  0.45643146\n",
      "  -0.09096967 -0.20169721 -0.19296709 -0.21690052  0.25070205 -0.23023138\n",
      "  -0.03330118  0.4733284  -0.35603835 -0.10050169 -0.09384869  0.43991834\n",
      "  -0.19479662 -0.56313065 -1.30427908  3.43687634 -0.51755585  0.2950065\n",
      "   0.46488627 -0.06621145  0.13548475 -0.00485725 -0.22665974  0.08720162\n",
      "   0.14723842 -0.83607855  0.28948853  0.27822622 -0.21871972  0.74248372\n",
      "  -0.52760594  0.02854754 -0.04304787  0.04070483 -1.29277245 -0.12920034\n",
      "  -0.26148414  0.32378132  1.01330152 -0.45140657  0.49669555 -0.22672213\n",
      "  -0.61701859  0.64456007 -0.36875573 -0.9554094 ]]\n",
      "Intercept: [0.17992805]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yukse\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.87\n",
      "best value of parameter C: 0.87\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "\n",
    "reg_full = linear_model.LogisticRegression(dual=False, tol=0.0001, C=5000000, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None)  #ADD CODE\n",
    "reg_full.fit(X_training, Y_training)\n",
    "\n",
    "# the coefficients from the logistic regression model.\n",
    "print(\"Coefficients obtained using the entire training set: {}\".format( reg_full.coef_ ))\n",
    "print(\"Intercept: {}\".format( reg_full.intercept_ ))\n",
    "\n",
    "# Plot the coefficients\n",
    "reg_coef = reg_full.coef_.reshape(reg_full.coef_.shape[1],)\n",
    "plt.figure()\n",
    "ind = np.arange(1,len(reg_coef)+1)  # the x locations for the groups\n",
    "width = 0.45       # the width of the bars\n",
    "plt.bar(ind, reg_coef, width, color='r')\n",
    "plt.xlabel('Coefficient Index')\n",
    "plt.ylabel('Coefficient Value')\n",
    "plt.title('Logistic Regression Coefficients')\n",
    "plt.show()\n",
    "\n",
    "reg_full_best_accuracy = reg_full.score(X_training,Y_training)\n",
    "print(reg_full_best_accuracy)\n",
    "print(\"best value of parameter C: {}\".format( reg_full_best_accuracy ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.87\n",
      "Test Accuracy: 0.5974499089253188\n"
     ]
    }
   ],
   "source": [
    "# prediction on training data\n",
    "Y_training_prediction_LR = reg.predict(X_training) # COMPLETE\n",
    "\n",
    "# accuracy for training dataset\n",
    "print(\"Training Accuracy:\", metrics.accuracy_score(Y_training, Y_training_prediction_LR))\n",
    "# COMPLETE\n",
    "\n",
    "# prediction on test data\n",
    "Y_test_prediction_LR = reg.predict(X_test) # COMPLETE\n",
    "111\n",
    "# accuracy for test dataset\n",
    "print(\"Test Accuracy:\", metrics.accuracy_score(Y_test, Y_test_prediction_LR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values of parameter C tried in 10-fold Cross-Validation: [60000]\n",
      "Accuracies obtained for the different values of C with 10-fold Cross-Validation: [0.53]\n",
      "Best value of C with 10-fold Cross-Validation: [60000]\n",
      "[[0.6]\n",
      " [0.4]\n",
      " [0.7]\n",
      " [0.5]\n",
      " [0.4]\n",
      " [0.3]\n",
      " [0.8]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.6]]\n",
      "10-fold Cross-Validation accuracies obtained with the best value of parameter C: 0.8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.7, solver='newton-cg')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# L2 regularized logistic regression with cross-validation\n",
    "\n",
    "regL2 = linear_model.LogisticRegressionCV(Cs=[60000], solver='newton-cg',cv=10, penalty='l2') \n",
    "regL2.fit(X_training, Y_training) \n",
    "\n",
    "# the values of C evaluated in cross-validation;\n",
    "print(\"Values of parameter C tried in 10-fold Cross-Validation: {}\".format( regL2.Cs_ ))\n",
    "\n",
    "# the average accuracy across the 10 folds\n",
    "CV_accuracies = np.divide(np.sum(regL2.scores_[1],axis=0),10)\n",
    "\n",
    "# the average accuracies obtained for the various values of C\n",
    "print(\"Accuracies obtained for the different values of C with 10-fold Cross-Validation: {}\".format( CV_accuracies ))\n",
    "\n",
    "# the best value of C as identified by cross-validation;\n",
    "print(\"Best value of C with 10-fold Cross-Validation: {}\".format( regL2.C_ ))\n",
    "\n",
    "# the best CV accuracy\n",
    "print(regL2.scores_[1])\n",
    "regL2_best_CV_accuracy = np.max(regL2.scores_[1])\n",
    "print(\"10-fold Cross-Validation accuracies obtained with the best value of parameter C: {}\".format( regL2_best_CV_accuracy ))\n",
    "\n",
    "# the model using the best C\n",
    "regL2_best = linear_model.LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=0.7, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='newton-cg', max_iter=100, multi_class='auto', verbose=0, warm_start=False, n_jobs=None, l1_ratio=None) \n",
    "# COMPLETE\n",
    "# the model using the best C on the entire training set\n",
    "regL2_best.fit(X_training, Y_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients obtained using the entire training set: [[ 0.88094966 -0.88094966 -0.41538158  0.41538158  0.13835414 -0.34495143\n",
      "   0.34495143  0.09470007 -0.09470007  0.03643915 -0.03643915 -3.02832882\n",
      "  -0.65225711  0.05383952  1.24919037  0.05261164 -0.01878807  0.45643146\n",
      "  -0.09096967 -0.20169721 -0.19296709 -0.21690052  0.25070205 -0.23023138\n",
      "  -0.03330118  0.4733284  -0.35603835 -0.10050169 -0.09384869  0.43991834\n",
      "  -0.19479662 -0.56313065 -1.30427908  3.43687634 -0.51755585  0.2950065\n",
      "   0.46488627 -0.06621145  0.13548475 -0.00485725 -0.22665974  0.08720162\n",
      "   0.14723842 -0.83607855  0.28948853  0.27822622 -0.21871972  0.74248372\n",
      "  -0.52760594  0.02854754 -0.04304787  0.04070483 -1.29277245 -0.12920034\n",
      "  -0.26148414  0.32378132  1.01330152 -0.45140657  0.49669555 -0.22672213\n",
      "  -0.61701859  0.64456007 -0.36875573 -0.9554094 ]]\n",
      "Intercept: [0.17992805]\n",
      "Coefficients obtained using the entire training set: [[ 3.87883167e-01 -3.87883167e-01 -2.63586480e-01  2.63586480e-01\n",
      "   2.08524727e-01 -1.02781868e-01  1.02781868e-01  3.02491926e-02\n",
      "  -3.02491926e-02  6.47842497e-02 -6.47842497e-02 -5.64574755e-01\n",
      "  -3.20118764e-01 -2.38225945e-02  6.49535162e-01 -1.55450807e-01\n",
      "   2.93045851e-05  2.17374505e-01 -1.65558278e-01 -1.66599408e-01\n",
      "   1.20465554e-01 -1.65160707e-01  1.84559124e-01 -1.63399885e-01\n",
      "   5.03800813e-02  2.48992470e-01 -7.92164826e-02 -1.52894312e-01\n",
      "  -9.24470571e-02  2.69108568e-01 -1.18395429e-01  4.76456332e-02\n",
      "  -3.00605489e-01  4.82534016e-01 -2.01315522e-01  7.50487720e-02\n",
      "   2.39678142e-01 -1.03542306e-02  2.02857521e-01 -6.37974076e-03\n",
      "  -2.83995645e-01  4.11826890e-02 -1.44740447e-03 -2.15611697e-01\n",
      "   1.49791262e-01  1.11300945e-01 -1.45469611e-01  1.32715900e-01\n",
      "  -2.53839567e-01  6.14030626e-02  6.26356982e-02  8.58293938e-03\n",
      "  -6.91858124e-01 -1.35444791e-01 -5.42351170e-02  2.12507393e-01\n",
      "   4.66594023e-01 -2.49123775e-01  1.18238149e-01 -6.11253856e-02\n",
      "  -3.22097643e-01  3.94107435e-01 -7.49251341e-02 -6.31975462e-01]]\n",
      "Intercept: [-0.27005238]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The coefficients from logistic regression\n",
    "print(\"Coefficients obtained using the entire training set: {}\".format( reg_full.coef_ ))\n",
    "# the coefficients from L2 regularized logistic regression\n",
    "print(\"Intercept: {}\".format( reg_full.intercept_ ))\n",
    "\n",
    "regL2_full = linear_model.LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=0.7, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='newton-cg', max_iter=100, multi_class='auto', verbose=0, warm_start=False, n_jobs=None, l1_ratio=None)\n",
    "regL2_full.fit(X_training, Y_training)\n",
    "print(\"Coefficients obtained using the entire training set: {}\".format( regL2_full.coef_ ))\n",
    "print(\"Intercept: {}\".format( regL2_full.intercept_ ))\n",
    "\n",
    "# Plot the coefficients\n",
    "regL2_full_coef = regL2_full.coef_.reshape(regL2_full.coef_.shape[1],)\n",
    "ind = np.arange(1,len(reg_coef)+1)  # the x locations for the groups\n",
    "width = 0.35       # the width of the bars\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "rects1 = ax.bar(ind, reg_coef, width, color='r')\n",
    "rects2 = ax.bar(ind + width, regL2_full_coef, width, color='g')\n",
    "ax.legend((rects1[0], rects2[0]), ('Log Regr', 'Log Regr + L2 Regul'))\n",
    "plt.xlabel('Coefficient Idx')\n",
    "plt.ylabel('Coefficient Value')\n",
    "plt.title('Logistic Regression Coefficients: Standard and Regularized Version')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
